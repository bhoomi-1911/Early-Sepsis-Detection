# -*- coding: utf-8 -*-
"""03_ModelTraining.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/187gMFQBnjzKblYSOYZ59YavNPUOrwiuF

Import all the libraries
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from imblearn.under_sampling import RandomUnderSampler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

"""Load the data"""

df = pd.read_csv('/content/drive/MyDrive/Sepsis Prediction/aggregated_data1.csv')

"""Initalizing dependants and target with train and test data"""

X = df.drop(columns=['SepsisLabel','Patient_ID'])
y = df['SepsisLabel']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

"""Undersampling"""

rus = RandomUnderSampler(random_state=42)
X_train_res, y_train_res = rus.fit_resample(X_train, y_train)

print("After undersampling:")
print(pd.Series(y_train_res).value_counts())

"""Training the model"""

rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
rf.fit(X_train_res, y_train_res)

"""Prediction"""

y_pred = rf.predict(X_test)
y_proba = rf.predict_proba(X_test)[:,1]

"""Classification Report"""

print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("ROC-AUC:", roc_auc_score(y_test, y_proba))

"""Confusion Matrix"""

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - RF with Undersampling')
plt.show()

"""Tuning hyperparameters"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score

# Base RF model
rf = RandomForestClassifier(random_state=42, n_jobs=-1)

def run_grid_search(param_grid, X_train, y_train):
    grid = GridSearchCV(
        estimator=rf,
        param_grid=param_grid,
        scoring='roc_auc',
        cv=3,
        verbose=2,
        n_jobs=-1
    )
    grid.fit(X_train, y_train)
    print(f"Best Parameters: {grid.best_params_}")
    print(f"Best ROC-AUC: {grid.best_score_}")
    return grid.best_estimator_

param_grid_depth = {'max_depth': [5, 10, 15, 20, None]}
best_rf = run_grid_search(param_grid_depth, X_train_res, y_train_res)

param_grid_split = {'min_samples_split': [2, 5, 10, 20]}
best_rf = run_grid_search(param_grid_split, X_train_res, y_train_res)

param_grid_leaf = {'min_samples_leaf': [1, 2, 4, 8]}
best_rf = run_grid_search(param_grid_leaf, X_train_res, y_train_res)

param_grid_features = {'max_features': ['sqrt', 'log2', None, 0.5]}
best_rf = run_grid_search(param_grid_features, X_train_res, y_train_res)

param_grid_weight = {'class_weight': [None, 'balanced', 'balanced_subsample']}
best_rf = run_grid_search(param_grid_weight, X_train_res, y_train_res)

param_grid_estimators = {'n_estimators': [100, 200, 500, 1000]}
best_rf = run_grid_search(param_grid_estimators, X_train_res, y_train_res)

"""Training the model with best parameters"""

from sklearn.ensemble import RandomForestClassifier

final_rf = RandomForestClassifier(
    max_depth=15,
    min_samples_split=20,
    min_samples_leaf=8,
    max_features=None,
    class_weight='balanced_subsample',
    n_estimators=1000,
    random_state=42,
    n_jobs=-1
)

final_rf.fit(X_train_res, y_train_res)

y_pred = final_rf.predict(X_test)
y_pred_proba = final_rf.predict_proba(X_test)[:, 1]

print("Classification Report:")
print(classification_report(y_test, y_pred))
roc_auc = roc_auc_score(y_test, y_pred_proba)
print(f"ROC-AUC Score: {roc_auc:.4f}")

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt

fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.figure(figsize=(6, 4))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - RF with Undersampling')
plt.show()

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Get predicted probabilities
y_pred_proba = final_rf.predict_proba(X_test)[:, 1]

# Adjust threshold (lower than 0.5 to catch more positives)
threshold = 0.437 # try 0.4, 0.35, etc.
y_pred_adjusted = (y_pred_proba >= threshold).astype(int)

# Evaluate again
print(f"Classification Report (Threshold={threshold}):")
print(classification_report(y_test, y_pred_adjusted))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_adjusted))

from sklearn.feature_selection import SelectFromModel

def add_engineered_features(df):
    df = df.copy()

    # Ratios
    if {'HR_mean', 'HR_min'}.issubset(df.columns):
        df['HR_mean_HR_min_ratio'] = df['HR_mean'] / (df['HR_min'] + 1e-6)

    if {'SpO2_mean', 'SpO2_min'}.issubset(df.columns):
        df['SpO2_mean_SpO2_min_ratio'] = df['SpO2_mean'] / (df['SpO2_min'] + 1e-6)

    if {'HR_mean', 'Age'}.issubset(df.columns):
        df['HR_mean_age_ratio'] = df['HR_mean'] / (df['Age'] + 1e-6)

    # Differences
    if {'HR_max', 'HR_min'}.issubset(df.columns):
        df['HR_range'] = df['HR_max'] - df['HR_min']

    if {'SpO2_max', 'SpO2_min'}.issubset(df.columns):
        df['SpO2_range'] = df['SpO2_max'] - df['SpO2_min']

    # Interaction
    if {'HR_mean', 'Resp_mean'}.issubset(df.columns):
        df['HR_Resp_interaction'] = df['HR_mean'] * df['Resp_mean']

    return df

df_eng = add_engineered_features(df)

X = df_eng.drop(columns=['SepsisLabel'])
y = df_eng['SepsisLabel']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

rus = RandomUnderSampler(random_state=42)
X_train_res, y_train_res = rus.fit_resample(X_train, y_train)

"""Feature Selection"""

selector = SelectFromModel(RandomForestClassifier(random_state=42), threshold="median")
selector.fit(X_train_res, y_train_res)

X_train_res_sel = selector.transform(X_train_res)
X_test_sel = selector.transform(X_test)

final_rf.fit(X_train_res_sel, y_train_res)

y_pred = final_rf.predict(X_test_sel)
y_proba = final_rf.predict_proba(X_test_sel)[:,1]

print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(roc_auc_score(y_test, y_proba))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - RF with Undersampling')
plt.show()

import joblib
joblib.dump(final_rf, "final_rf_model.pkl")
from google.colab import files
files.download("final_rf_model.pkl")